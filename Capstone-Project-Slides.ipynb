{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BC Data Workshop - Video Compression Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The quality of video is affected by the video capture, compression,  transmission, and also by factors on the audience end. We present a non-exhaustive tour of some important features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Resolution : number of pixels displayed and/or captured. **   \n",
    "- 720 x 480 (or 480p) \"SD\"\n",
    "- 3840 x 2160 (or 2160p) \"4K\"  \n",
    "- The content of the scene may dictate the necessary resolution, e.g. the level of detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Framerate: rate at which frames are displayed. **  \n",
    "- Increasing the framerate (fps) will result in a smoother video at a given resolution. \n",
    "- Standards for framerate vary from media to media. \n",
    "- Content of the scene may require a higher framerate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "** Bitrate: Size of video file streaming per second. **\n",
    "\n",
    "- trade-off between quality and storage/cost (also possible lags/buffering if streaming)\n",
    "- Need to ensure that most user's have adequate bandwith. \n",
    "- Higher resolution &/or framerate requires higher bitrate\n",
    "\n",
    "In general, we want to be able to reduce bitrate while maintaining quality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Video Compression\n",
    "\n",
    "** Frame-by-Frame encoding **   \n",
    "- Compress each individual frame \n",
    "- e.g. JPEG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Temporal encoding **  \n",
    "\n",
    "- Attempt to only store the changes between frames\n",
    "\n",
    "- e.g. H.264 and MPEG-4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Basic framework: we encode frames as one of three frame type: Intra(I)-frames, Predicted(P)-frames and Bidirectional(B)-frames. \n",
    "- I-Frames : complete encoded images \n",
    "- P-Frames : coded with reference to an earlier I- or P-frame. \n",
    "- B-Frames : contain information on the changes between previous and following frames.\n",
    "\n",
    "On average, using H264, we can reduce bitrate by ~50% for fixed quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A first look at the data\n",
    "\n",
    "Our goal will be to create a model which predicts bitrate given various camera and scene features. \n",
    "\n",
    "Bitrate measurements were taken after capturing and compressing video taken under different test conditions (listed below). \n",
    "\n",
    "The data was provided by Roger Donaldson (Midvale Applied Mathematics).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Camera Features (from 8 different cameras)\n",
    "- Flicker: camera cuts out light flicker, depending on the region\n",
    "- KeyFrame: number of P- and B-frames between I-frames (minus 1)\n",
    "- ImageRate: framerate (fps)\n",
    "- Quality: compression control, low number is best quality\n",
    "- Nonlinear: single or multi-exposure frames (HDR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Mode: high performance or standard modes\n",
    "- Compression: additional compression mode\n",
    "- KpbsLimit: user set maximum bitrate\n",
    "- Primary Resolution: highest resolution stream\n",
    "- Secondary Resolution: lower resolution stream\n",
    "- Tertiary Resolution: lowest resolution stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scene Features\n",
    "- Test: type of test (Base, Idle, Compression, or HDR)\n",
    "- Motion: amount of motion in scene, classified as high, medium or none\n",
    "- Detail: the amount of detial in scene, classified as high, medium, or low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Measurements\n",
    "- CollectSeconds: time of data collection\n",
    "- WaitSeconds: time between measurements\n",
    "- TotalBytes: total number of bytes transmitted to the network\n",
    "- Primary Bitrate: mean bitrate for primary stream\n",
    "- Secondary Bitrate: mean bitrate for secondary stream\n",
    "- Tertiary Bitrate: mean bitrate for tertiary stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocessing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "datadir = '/home/nmulberry/data/1-Donaldson/'\n",
    "datafile = 'AllData.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 50\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing data by Aaron\n",
    "def checkColumn(df, colNum):\n",
    "    \"\"\"\n",
    "    Used in throwAwayUnchanged\n",
    "    \"\"\"\n",
    "    return np.all(df.iloc[0, colNum] == df.iloc[1:, colNum])\n",
    "\n",
    "def removeUnwantedCols(data):\n",
    "    drop_cols = ['Flicker','Index','Sharpening','TotalBytes','Status','Message',\n",
    "                 'TertiaryBitsPerSecond','TertiaryResolution']\n",
    "    for c in drop_cols:\n",
    "        data = data.drop(c,axis=1)\n",
    "    data.groupby('Mode').get_group(0)\n",
    "    data = removeUnchanging(data)\n",
    "    return data\n",
    "\n",
    "def removeUnchanging(data):\n",
    "    idxUnhelpful = [j for j in range(data.columns.size) if checkColumn(data,j)]\n",
    "    data = data.drop(data.columns[idxUnhelpful],axis=1)    \n",
    "    return data\n",
    "\n",
    "def fixMiscValues(data):\n",
    "    data = data.fillna({'TertiaryResolution' : 'NaN'})\n",
    "    data = data.replace('-', value=0)\n",
    "    data['SecondaryBitsPerSecond'] = data['SecondaryBitsPerSecond'].astype(np.float64)\n",
    "    #data['TertiaryBitsPerSecond'] = data['TertiaryBitsPerSecond'].astype(np.float64)\n",
    "    return data\n",
    "\n",
    "def appendFeatureName(data):\n",
    "    cols = ['Compression','Test','Detail','Motion','CameraName','PrimaryResolution','SecondaryResolution']\n",
    "    for c in cols:\n",
    "        data[c] = data[c].apply(lambda x: c + '_' + x)\n",
    "    return data\n",
    "\n",
    "def logTransformColumn(data, colname):\n",
    "    \"\"\"\n",
    "    Tailor-made for the Midvale data. \n",
    "    log-transforms the columns pertaining to bit-rate.\n",
    "    \"\"\"\n",
    "    logBytes = data[colname]\n",
    "    logBytes = logBytes.replace(0., np.nan).apply(lambda x: np.log10(x))\n",
    "    logBytes = logBytes.dropna(how='all')\n",
    "    return data.assign(**{'log'+logBytes.name: logBytes})\n",
    "\n",
    "def addLogCols(data):\n",
    "    for columnName in ['PrimaryBitsPerSecond', \n",
    "                       'SecondaryBitsPerSecond']:\n",
    "        data = logTransformColumn(data, columnName)\n",
    "    return data\n",
    "\n",
    "def preProcess(data):\n",
    "    data = removeUnwantedCols(data)\n",
    "    data = fixMiscValues(data)\n",
    "    data = addLogCols(data)\n",
    "    data = appendFeatureName(data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(datadir + datafile)\n",
    "data = preProcess(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "numerical_names = ['Keyframe', 'ImageRate', 'Quality', 'KbpsLimit']\n",
    "numerical = data.filter(items=numerical_names)\n",
    "\n",
    "categ_names = ['PrimaryResolution', 'SecondaryResolution', 'Detail', 'Test', \n",
    "               'Motion','CameraName','Nonlinear','Mode','Compression']\n",
    "categ = data.filter(items=categ_names)\n",
    "\n",
    "response_names = ['logPrimaryBitsPerSecond', 'logSecondaryBitsPerSecond']\n",
    "responses = data.filter(items=response_names)\n",
    "\n",
    "excluded_names = [j for j in data.columns if (j not in categ_names and j not in numerical_names and j not in response_names and j not in ['PrimaryBitsPerSecond','SecondaryBitsPerSecond']) ]\n",
    "print('Included numerical features',numerical_names)\n",
    "print('Included categorical features',categ_names)\n",
    "print('Excluded features',excluded_names)\n",
    "\n",
    "# Data processing by Aaron\n",
    "def categDF(data):\n",
    "    categoricals = data.select_dtypes(include=['object'])\n",
    "    #categoricals = categoricals.drop('Message', axis=1)\n",
    "    return categoricals\n",
    "\n",
    "def setUpCategs(data, sparse=False):\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    lb = LabelEncoder()\n",
    "    oh = OneHotEncoder()\n",
    "    categoricals = categDF(data)\n",
    "    categoricals = categoricals.apply(lb.fit_transform)\n",
    "    categoricals = oh.fit_transform(categoricals)\n",
    "    if not sparse:\n",
    "        categoricals = categoricals.toarray()\n",
    "    return categoricals\n",
    "\n",
    "def unencodeOneHotLabelling(ohEnc, oh, lbl):\n",
    "    return lbl.inverse_transform(oh.active_features_)[np.argmax(ohEnc, axis=-1)]\n",
    "\n",
    "categoricals = setUpCategs(categ)\n",
    "categ_data = categDF(categ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "logBytes = data.loc[:, ['PrimaryBitsPerSecond', 'SecondaryBitsPerSecond']]\n",
    "logBytes = logBytes.replace(0., np.nan).apply(lambda x: np.log(x)).dropna(how='all')\n",
    "logBytes.hist(figsize=(10,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def logTransformColumn(df, colname):\n",
    "    \"\"\"\n",
    "    Tailor-made for the Midvale data. \n",
    "    log-transforms the columns pertaining to bit-rate.\n",
    "    \"\"\"\n",
    "    logBytes = data[colname]\n",
    "    logBytes = logBytes.replace(0., np.nan).apply(lambda x: np.log(x))\n",
    "    logBytes = logBytes.dropna(how='all')\n",
    "    return df.assign(**{'log'+logBytes.name: logBytes})\n",
    "\n",
    "def logTransformBytes(df):\n",
    "    for columnName in ['PrimaryBitsPerSecond', \n",
    "                       'SecondaryBitsPerSecond']:\n",
    "        df = logTransformColumn(df, columnName)\n",
    "    return df\n",
    "\n",
    "data = logTransformBytes(data)\n",
    "\n",
    "def hist_colVals(X, **kwargs):\n",
    "    \"\"\"\n",
    "    X : a categorical column of a data frame\n",
    "    \"\"\"\n",
    "    # Check if not categorical\n",
    "    #\n",
    "    #\n",
    "    # get value counts\n",
    "    vc = X.value_counts()\n",
    "    n = vc.shape[0]\n",
    "    xrange = np.arange(n)\n",
    "    plt.bar(xrange, vc.values, **kwargs)\n",
    "    plt.xticks(xrange, vc.index.tolist(), rotation=90)\n",
    "    return\n",
    "    \n",
    "    # make a histogram of these\n",
    "# (these are the *useful* categories for CamerName:A3;Test:Base)\n",
    "categs = ['PrimaryResolution', 'SecondaryResolution', \n",
    "          'Keyframe', 'ImageRate', 'Quality',\n",
    "          'Detail', 'Motion']\n",
    "\n",
    "C = len(categs)\n",
    "ncols = 4\n",
    "nrows = np.int(np.ceil(C/5))\n",
    "figwidth = 20\n",
    "figheight = np.int(np.min([np.ceil(20/ncols*nrows), 20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(figwidth, figheight))\n",
    "fig.subplots_adjust(hspace=.75)\n",
    "\n",
    "for j, categ in enumerate(categs):\n",
    "    plt.subplot(nrows, ncols, j+1)\n",
    "    hist_colVals(data[categ])\n",
    "    plt.xlabel(categ, labelpad=20)\n",
    "for j in range(C, nrows*ncols):\n",
    "    plt.subplot(nrows, ncols, j+1)\n",
    "    plt.axis('off')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data['logPrimaryBitsPerSecond'].hist(bins=1000, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getCategNames(df):\n",
    "    return np.concatenate([np.unique(df[col].values) for col in df.columns])\n",
    "\n",
    "def unencodeOneHot(ohArr, df):\n",
    "    categNames = getCategNames(df)\n",
    "    return [categNames[np.where(ohArr)[1]][j::2] for j in range(2)]\n",
    "\n",
    "categ_names = getCategNames(categ_data)\n",
    "data_names = np.concatenate((numerical_names, categ_names))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = np.hstack((scaler.fit_transform(numerical.values), categoricals))\n",
    "y = responses.values\n",
    "y_pbps = y[:, 0]\n",
    "nonnanrows = [not np.isnan(y_pbps[j]) for j in range(y_pbps.shape[0])]\n",
    "X_nonnan = X[nonnanrows, :]\n",
    "y_nonnan = y_pbps[nonnanrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X_nonnan,y_nonnan)\n",
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nfeat = X_train.shape[1]\n",
    "print('# of training samples {}'.format(ntrain))\n",
    "print('# of test samples {}'.format(ntest))\n",
    "print('# of features {}'.format(nfeat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Output statistics for after regression\n",
    "res_func_inv = lambda x: 10**x\n",
    "pdeviation = 0.2\n",
    "def RMSE(output, prediction):\n",
    "    return np.sqrt(np.mean((res_func_inv(output) - res_func_inv(prediction))**2))\n",
    "def NRMSE(output, prediction):\n",
    "    return RMSE(output,prediction)/(np.max(res_func_inv(output))-np.min(res_func_inv(output)))\n",
    "def percentHits(output,prediction,pdeviation):\n",
    "    return np.mean( np.abs(res_func_inv(output)-res_func_inv(prediction))<pdeviation*abs(res_func_inv(output)) )\n",
    "\n",
    "def regressionSummary(method,Xtrain,Ytrain,Xtest,Ytest):\n",
    "    predict_train = method.predict(Xtrain)\n",
    "    train_nrmse = NRMSE(Ytrain,predict_train)\n",
    "    train_hits = percentHits(Ytrain,predict_train,pdeviation)\n",
    "    Rsq_train = method.score(Xtrain,Ytrain)\n",
    "    predict_test = method.predict(Xtest)    \n",
    "    test_nrmse = NRMSE(Ytest,predict_test)\n",
    "    test_hits = percentHits(Ytest,predict_test,pdeviation)\n",
    "    Rsq_test = method.score(Xtest,Ytest)\n",
    "    print('Regression results for ',method.__class__)\n",
    "    print('------Training data------')\n",
    "    print('NRMSE = {}'.format(train_nrmse))\n",
    "    print('Percentage of values with <',pdeviation*100,'percent rel err =',train_hits)\n",
    "    print('R^2 = {}'.format(Rsq_train))\n",
    "    print('------Test data----------')\n",
    "    print('NRMSE = {}'.format(test_nrmse))\n",
    "    print('Percentage of values with <',pdeviation*100,'percent rel err =',test_hits)\n",
    "    print('R^2 = {}'.format(Rsq_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plain linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "regressionSummary(lr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Plain elastic net\n",
    "if ntrain < 5000:\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    en = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], n_jobs=-1)\n",
    "    en.fit(X_train,y_train)\n",
    "    regressionSummary(en,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Kernel ridge regression - takes a while\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "kr = KernelRidge(alpha=1,kernel='rbf',gamma=0.1)\n",
    "kr.fit(X_train,y_train)\n",
    "regressionSummary(kr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest Regression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=10)\n",
    "rf.fit(X_train,y_train)\n",
    "regressionSummary(rf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Extra Trees Regression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "et = ExtraTreesRegressor()\n",
    "et.fit(X_train,y_train)\n",
    "regressionSummary(et,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting - takes a while\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor(n_estimators=100)\n",
    "gb.fit(X_train,y_train)\n",
    "regressionSummary(gb,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Feature importances for Extra Trees Regressor\n",
    "importances = et.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in et.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "dispindex = np.where(importances[indices] < 0.05*importances[indices][0])[0][0]\n",
    "importances_trunc = importances[indices][:dispindex]\n",
    "names_trunc = data_names[indices][:dispindex]\n",
    "std_trunc = std[indices][:dispindex]\n",
    "plt.figure()\n",
    "plt.bar(range(dispindex),importances_trunc,color=\"r\",yerr=std_trunc)\n",
    "plt.xticks(range(dispindex),names_trunc,rotation='vertical')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the cumulative regression performance for each method\n",
    "p = np.linspace(0.5,0.05,num=10)\n",
    "def cumul_regress_performance(re,Xtest,Ytest):\n",
    "    pred = re.predict(Xtest)\n",
    "    percent = np.zeros(len(p))\n",
    "    for i in range(len(p)):\n",
    "        percent[i] = percentHits(Ytest,pred,p[i])\n",
    "    return percent\n",
    "\n",
    "regr_methods = [lr,kr,rf,et,gb]\n",
    "performance = []\n",
    "for m in regr_methods:\n",
    "    performance.append(cumul_regress_performance(m,X_test,y_test))\n",
    "nmethods = len(regr_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10,5))\n",
    "regr_labels = ['LinReg','KernRidge','RandForest','ExtraTrees','GradBoost']\n",
    "for i in range(nmethods):\n",
    "    plt.plot(range(len(p)),100*performance[i],label=regr_labels[i])\n",
    "\n",
    "plt.xlabel('Relative error rate')\n",
    "plt.ylabel('% Predicted within rel. err')\n",
    "plt.xticks(range(len(p)),100*p)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
