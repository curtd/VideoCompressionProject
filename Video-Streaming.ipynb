{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The quality of video is affected by the video capture, compression,  transmission, and also by factors on the audience end. We present a non-exhaustive tour of some important features.\n",
    "\n",
    "** Resolution : number of pixels displayed and/or captured. **   \n",
    "Commonly,\n",
    "- 720 x 480 (or 480p) \"SD\"\n",
    "- 1280 x 720 (or 720p)\"HD\"\n",
    "- 1920 x 1080 (or 1080p) \"Full HD\"\n",
    "- 2560 x 1440 (or 1440p) \"QHD\"\n",
    "- 3840 x 2160 (or 2160p) \"4K\"\n",
    "- 7680 x 4320 (or 4320p) \"8K\"  \n",
    "  \n",
    "Higher resolution does  not necessarily lead to higher quality: need to take into account monitor of device on which the video will be streamed. The content of the scene may dictate the necessary resolution, e.g. the level of detail.\n",
    "\n",
    "** Framerate: rate at which frames are displayed. **\n",
    "Increasing the framerate (fps) will result in a smoother video at a given resolution. Standards for framerate vary from media to media. A typical computer screen has a framerate of 60fps. Movie theatres use a framerate of 24 fps. Again, the content of the scene may also require a higher framerate, e.g. the level of motion.\n",
    "\n",
    "** Bitrate: Size of video file streaming per second. **\n",
    "\n",
    "Choosing an appropriate bitrate is a trade-off between quality and storage/cost (also possible lags/buffering if streaming). Need to ensure that most user's have adequate bandwith. \n",
    "Data may be captured at high resolution, but then sampled down for cost/efficiency: higher resolution requires higher bitrate...Naturally, a higher framerate will also require higher bitrate.\n",
    "\n",
    "In general, we want to be able to reduce bitrate while maintaining quality, which is where video compression comes in.\n",
    "\n",
    "\n",
    "## Video Compression\n",
    "\n",
    "** Frame-by-Frame encoding ** \n",
    "Compress each individual frame, resulting in a series of compressed images. Since no information from other frames is required for compresison, the data can be compressed, transmitted, decompressed and then displayed rapidly (low latency). There is also no risk of invalid frames caused by the algorithm, which is useful for surveillance. The static-image compression algorithms used are generally JPEG or JPEG2000. \n",
    "\n",
    "** Temporal encoding **\n",
    "With temporal encoding, we also consider changes from frame to frame, attempting to only store the changes between frames. This can lead to more savings than frame-by-frame encoding, but runs a risk of missing information. Standard codecs (enocding/decoding algorithms) are H.264 and MPEG-4.\n",
    "\n",
    "In the basic MPEG-4, we encode frames as one of three frame type: Intra(I)-frames, Predicted(P)-frames and Bidirectional(B)-frames. \n",
    "- I-Frames are complete encoded images (can be decoded without reference to other frames). Needed as starting points and reference points. They contain no artifacts, but are, on the other hand, more expensive. \n",
    "- P-Frames are coded with reference to an earlier I- or P-frame. This reference is in general complex and, as such, they are sensitive to transmission errors. They require fewer bits than I-frames.\n",
    "- B-Frames contain information on the changes between previous and following frames. Lower latency can be achieved without using B-frames.\n",
    "\n",
    "H.264 is an extension on MPEG-4. Additonal features include motion compensation (used in P- and B-frames): motion vectors are used to describe relative movement of an object from a reference frame. Computing the motion vector takes up fewer bits than if the whole content were to be coded (althout it is, in general, demanding). H.264 can also reduce the size of I-frames. On average, we can reduce bitrate by ~50% for fixed quality (less bandwith and storage space needed: higher quality at a lower bitrate!). This is, however, associated with a high latency (in general, though there are different \"levels\"), and high resolution cameras are required.\n",
    "\n",
    "In our data set (provided by Roger Donaldson of Midvale Applied Mathematics), we are given data on various camera, scene and transmission data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first look at the data\n",
    "\n",
    "Our goal will be to create a model which predicts bitrate given various camera and scene features.  Bitrate measurements were taken after capturing and compressing video taken under different test conditions (listed below). The data was provided by Roger Donaldson (Midvale Applied Mathematics).\n",
    "\n",
    "Important to keep in mind: in this dataset, we do not control for end-viewer quality of the video. We are interested instead in how these features affect the compression alogorithm of the camera, which in turns affects the bitrate.\n",
    "\n",
    "### Camera Features (from 8 different cameras)\n",
    "- Flicker: camera cuts out light flicker, depending on the region\n",
    "- KeyFrame: number of P- and B-frames between I-frames (minus 1)\n",
    "- ImageRate: framerate (fps)\n",
    "- Quality: compression control, low number is best quality\n",
    "- Nonlinear: single or multi-exposure frames (HDR)\n",
    "- Mode: high performance or standard modes\n",
    "- Compression: additional compression mode\n",
    "- KpbsLimit: user set maximum bitrate\n",
    "- Primary Resolution: highest resolution stream\n",
    "- Secondary Resolution: lower resolution stream\n",
    "- Tertiary Resolution: lowest resolution stream\n",
    "\n",
    "### Scene Features\n",
    "- Test: type of test (Base, Idle, Compression, or HDR)\n",
    "- Motion: amount of motion in scene, classified as high, medium or none\n",
    "- Detail: the amount of detial in scene, classified as high, medium, or low\n",
    "\n",
    "### Measurements\n",
    "- CollectSeconds: time of data collection\n",
    "- WaitSeconds: time between measurements\n",
    "- TotalBytes: total number of bytes transmitted to the network\n",
    "- Primary Bitrate: mean bitrate for primary stream\n",
    "- Secondary Bitrate: mean bitrate for secondary stream\n",
    "- Tertiary Bitrate: mean bitrate for tertiary stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
