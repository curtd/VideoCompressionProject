{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC Data Workshop - Video Compression Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = '/home/curtd/var/data/'\n",
    "datafile = 'A3.csv'\n",
    "localdatadir = '~/var/data/'\n",
    "localdatafile = 'TotalBytes.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 50\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data by Aaron\n",
    "def checkColumn(df, colNum):\n",
    "    \"\"\"\n",
    "    Used in throwAwayUnchanged\n",
    "    \"\"\"\n",
    "    return np.all(df.iloc[0, colNum] == df.iloc[1:, colNum])\n",
    "\n",
    "# Preprocessing data by Aaron\n",
    "def removeUnwantedCols(data):\n",
    "    drop_cols = ['Flicker','Index','Sharpening','TotalBytes','Status','Message']\n",
    "    for c in drop_cols:\n",
    "        data = data.drop(c,axis=1)\n",
    "    data.groupby('Mode').get_group(0)\n",
    "    data = removeUnchanging(data)\n",
    "    return data\n",
    "\n",
    "def removeUnchanging(data):\n",
    "    idxUnhelpful = [j for j in range(data.columns.size) if checkColumn(data,j)]\n",
    "    data = data.drop(data.columns[idxUnhelpful],axis=1)    \n",
    "    return data\n",
    "\n",
    "def fixMiscValues(data):\n",
    "    data = data.fillna({'TertiaryResolution' : 'NaN'})\n",
    "    data = data.replace('-', value=0)\n",
    "    data['SecondaryBitsPerSecond'] = data['SecondaryBitsPerSecond'].astype(np.float64)\n",
    "    #data['TertiaryBitsPerSecond'] = data['TertiaryBitsPerSecond'].astype(np.float64)\n",
    "    return data\n",
    "\n",
    "def logTransformColumn(data, colname):\n",
    "    \"\"\"\n",
    "    Tailor-made for the Midvale data. \n",
    "    log-transforms the columns pertaining to bit-rate.\n",
    "    \"\"\"\n",
    "    logBytes = data[colname]\n",
    "    logBytes = logBytes.replace(0., np.nan).apply(lambda x: np.log10(x))\n",
    "    logBytes = logBytes.dropna(how='all')\n",
    "    return data.assign(**{'log'+logBytes.name: logBytes})\n",
    "\n",
    "def addLogCols(data):\n",
    "    for columnName in ['PrimaryBitsPerSecond', \n",
    "                       'SecondaryBitsPerSecond']:\n",
    "        data = logTransformColumn(data, columnName)\n",
    "    return data\n",
    "\n",
    "def preProcess(data):\n",
    "    data = removeUnwantedCols(data)\n",
    "    data = fixMiscValues(data)\n",
    "    data = addLogCols(data)\n",
    "    return data\n",
    "\n",
    "# Read in data\n",
    "data = pd.read_csv(datadir + datafile)\n",
    "data = preProcess(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data processing by Aaron\n",
    "def setUpCategs(data, sparse=False):\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    lb = LabelEncoder()\n",
    "    oh = OneHotEncoder()\n",
    "    \n",
    "    categoricals = data.select_dtypes(include=['object'])\n",
    "    categoricals = pd.concat((categoricals, data['Nonlinear']), axis=1)\n",
    "    categoricals = categoricals.apply(lb.fit_transform)\n",
    "    categoricals = oh.fit_transform(categoricals)\n",
    "    if not sparse:\n",
    "        categoricals = categoricals.toarray()\n",
    "    return categoricals\n",
    "categoricals = setUpCategs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_names = ['Keyframe', 'ImageRate', 'Quality', 'KbpsLimit', 'CollectSeconds']\n",
    "numerical = data.filter(items=numerical_names)\n",
    "\n",
    "response_names = ['logPrimaryBitsPerSecond', 'logSecondaryBitsPerSecond']\n",
    "responses = data.filter(items=response_names)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = np.hstack((scaler.fit_transform(numerical.values), categoricals))\n",
    "y = responses.values\n",
    "y_pbps = y[:, 1]\n",
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X,y_pbps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output statistics for after regression\n",
    "res_func_inv = lambda x: 10**x\n",
    "pdeviation = 0.3\n",
    "def RMSE(output, prediction):\n",
    "    return np.sqrt(np.mean((res_func_inv(output) - res_func_inv(prediction))**2))\n",
    "def NRMSE(output, prediction):\n",
    "    return RMSE(output,prediction)/(np.max(res_func_inv(output))-np.min(res_func_inv(output)))\n",
    "def percentHits(output,prediction):\n",
    "    return np.mean( np.abs(res_func_inv(output)-res_func_inv(prediction))<pdeviation*abs(res_func_inv(output)) )\n",
    "\n",
    "def regressionSummary(method,Xtrain,Ytrain,Xtest,Ytest):\n",
    "    predict_train = method.predict(Xtrain)\n",
    "    train_nrmse = NRMSE(Ytrain,predict_train)\n",
    "    train_hits = percentHits(Ytrain,predict_train)\n",
    "    Rsq_train = method.score(Xtrain,Ytrain)\n",
    "    predict_test = method.predict(Xtest)    \n",
    "    test_nrmse = NRMSE(Ytest,predict_test)\n",
    "    test_hits = percentHits(Ytest,predict_test)\n",
    "    Rsq_test = method.score(Xtest,Ytest)\n",
    "    print('------Training data------')\n",
    "    print('NRMSE = {}'.format(train_nrmse))\n",
    "    print('Percentage of values with <',pdeviation*100,'percent rel err =',train_hits)\n",
    "    print('R^2 = {}'.format(Rsq_train))\n",
    "    print('------Test data----------')\n",
    "    print('NRMSE = {}'.format(test_nrmse))\n",
    "    print('Percentage of values with <',pdeviation*100,'percent rel err =',test_hits)\n",
    "    print('R^2 = {}'.format(Rsq_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "regressionSummary(lr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain elastic net\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "en = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], n_jobs=-1)\n",
    "en.fit(X_train,y_train)\n",
    "\n",
    "regressionSummary(en,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel ridge regression \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "kr = KernelRidge(alpha=1,kernel='rbf',gamma=0.1)\n",
    "kr.fit(X_train,y_train)\n",
    "regressionSummary(kr,X_train,y_train,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
